{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1c696b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e16bbc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b3d055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## AlexNet ##################\n",
    "def bn_relu(inplanes):\n",
    "    return nn.Sequential(nn.BatchNorm2d(inplanes), nn.ReLU(inplace=True))\n",
    "\n",
    "def bn_relu_pool(inplanes, kernel_size=3, stride=2):\n",
    "    return nn.Sequential(nn.BatchNorm2d(inplanes), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=kernel_size, stride=stride))\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 96, kernel_size=11, stride=4, bias=False)\n",
    "        self.relu_pool1 = bn_relu_pool(inplanes=96)\n",
    "        self.conv2 = nn.Conv2d(96, 192, kernel_size=5, padding=2, groups=2, bias=False)\n",
    "        self.relu_pool2 = bn_relu_pool(inplanes=192)\n",
    "        self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1, groups=2, bias=False)\n",
    "        self.relu3 = bn_relu(inplanes=384)\n",
    "        self.conv4 = nn.Conv2d(384, 384, kernel_size=3, padding=1, groups=2, bias=False)\n",
    "        self.relu4 = bn_relu(inplanes=384)\n",
    "        self.conv5 = nn.Conv2d(384, 256, kernel_size=3, padding=1, groups=2, bias=False)\n",
    "        self.relu_pool5 = bn_relu_pool(inplanes=256)\n",
    "        # classifier\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=5, groups=2, bias=False)\n",
    "        self.relu6 = bn_relu(inplanes=256)\n",
    "        self.conv7 = nn.Conv2d(256, num_classes, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu_pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu_pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        x = self.relu4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu_pool5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4911d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = AlexNet()\n",
    "net.load_state_dict(torch.load('./pytorch-models/cnn.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a5decd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.395, 3.857, 3.442, 3.744, 3.238, 3.512, 3.69, 3.6682, 3.818, 3.227, 3.0, 3.238, 3.232, 3.744, 3.395]\n",
      "[2, 4, 2, 3, 1, 2, 3, 3, 4, 1, 0, 1, 1, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "# Scaling of data\n",
    "valdir = './data/1/test16morph.txt'\n",
    "mylines = []                             # Declare an empty list named mylines.\n",
    "with open(valdir, 'rt') as myfile: # Open lorem.txt for reading text data.\n",
    "    for myline in myfile:                # For each line, stored as myline,\n",
    "        mylines.append(float(myline.split()[1]))       # add its contents to mylines.\n",
    "print(mylines)   \n",
    "\n",
    "min_val = min(mylines)\n",
    "max_val = max(mylines)\n",
    "lower_scale = 0\n",
    "upper_scale = 4\n",
    "\n",
    "for i in range(len(mylines)):\n",
    "    mylines[i] = int(round(((upper_scale-lower_scale)*((mylines[i]-min_val)/(max_val-min_val)))+lower_scale))\n",
    "    \n",
    "print(mylines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5f73c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(root, filedir, transform=None):\n",
    "    # Data loading\n",
    "    with open(filedir, 'r') as f:\n",
    "        lines = f.readlines()  \n",
    "    output = []    \n",
    "    for line in lines:\n",
    "        linesplit = line.split('\\n')[0].split(' ')\n",
    "        #print(linesplit)\n",
    "        addr = linesplit[0]\n",
    "        #target = torch.Tensor([float(linesplit[1])])\n",
    "        img = Image.open(os.path.join(root, addr)).convert('RGB')\n",
    "\n",
    "        if transform is not None:\n",
    "            img = transform(img)\n",
    "        \n",
    "        output.append([img, 0]) #ÍBS: Changed target to 0\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf732611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hér\n",
      "./data/morph16 ./data/1/test16morph.txt\n",
      "[[tensor([[[ 0.2967,  0.1939,  0.1083,  ..., -0.6281, -0.5596, -0.4568],\n",
      "         [ 0.2796,  0.1939,  0.1083,  ..., -0.6281, -0.5596, -0.4739],\n",
      "         [ 0.2796,  0.1939,  0.1083,  ..., -0.6281, -0.5596, -0.4739],\n",
      "         ...,\n",
      "         [ 0.1426,  0.1083,  0.0569,  ...,  0.1939,  0.1597,  0.1083],\n",
      "         [ 0.0912,  0.0398,  0.0056,  ...,  0.1939,  0.1597,  0.1254],\n",
      "         [ 0.0227,  0.0056, -0.0116,  ...,  0.1768,  0.1597,  0.1254]],\n",
      "\n",
      "        [[ 0.1001,  0.0126, -0.0749,  ..., -0.8277, -0.7577, -0.6527],\n",
      "         [ 0.1001,  0.0126, -0.0749,  ..., -0.8277, -0.7577, -0.6877],\n",
      "         [ 0.1001,  0.0126, -0.0749,  ..., -0.8277, -0.7577, -0.6877],\n",
      "         ...,\n",
      "         [-0.1099, -0.1450, -0.1625,  ...,  0.0126, -0.0049, -0.0399],\n",
      "         [-0.1450, -0.1800, -0.2150,  ...,  0.0126, -0.0049, -0.0224],\n",
      "         [-0.1800, -0.1975, -0.2150,  ...,  0.0126, -0.0049, -0.0224]],\n",
      "\n",
      "        [[-0.0615, -0.1487, -0.2184,  ..., -0.9330, -0.8807, -0.8110],\n",
      "         [-0.0790, -0.1487, -0.2184,  ..., -0.9330, -0.8807, -0.8284],\n",
      "         [-0.0790, -0.1487, -0.2184,  ..., -0.9330, -0.8807, -0.8458],\n",
      "         ...,\n",
      "         [-0.2184, -0.2184, -0.2532,  ..., -0.0267, -0.0267, -0.0615],\n",
      "         [-0.2358, -0.2707, -0.2881,  ..., -0.0267, -0.0267, -0.0441],\n",
      "         [-0.2532, -0.2707, -0.2881,  ..., -0.0267, -0.0441, -0.0441]]]), 0], [tensor([[[-0.6281, -0.6623, -0.6965,  ..., -0.5596, -0.5596, -0.5253],\n",
      "         [-0.6623, -0.6965, -0.7137,  ..., -0.5938, -0.5596, -0.5424],\n",
      "         [-0.6623, -0.7137, -0.7308,  ..., -0.6109, -0.5596, -0.5424],\n",
      "         ...,\n",
      "         [-0.4054, -0.4397, -0.5082,  ..., -0.3712, -0.3027, -0.2342],\n",
      "         [-0.4054, -0.4397, -0.5082,  ..., -0.3541, -0.3027, -0.2171],\n",
      "         [-0.4226, -0.4568, -0.5082,  ..., -0.3541, -0.3027, -0.2342]],\n",
      "\n",
      "        [[-0.9503, -0.9853, -1.0028,  ..., -0.8627, -0.8452, -0.7927],\n",
      "         [-0.9853, -1.0028, -1.0203,  ..., -0.8978, -0.8627, -0.8277],\n",
      "         [-1.0028, -1.0203, -1.0378,  ..., -0.9153, -0.8803, -0.8452],\n",
      "         ...,\n",
      "         [-0.7227, -0.7927, -0.8452,  ..., -0.6352, -0.5826, -0.5301],\n",
      "         [-0.7402, -0.8102, -0.8452,  ..., -0.6176, -0.5826, -0.5126],\n",
      "         [-0.7402, -0.7927, -0.8452,  ..., -0.6176, -0.5826, -0.5301]],\n",
      "\n",
      "        [[-1.1247, -1.1596, -1.1596,  ..., -1.0201, -1.0027, -0.9678],\n",
      "         [-1.1596, -1.1770, -1.1770,  ..., -1.0550, -1.0201, -0.9853],\n",
      "         [-1.1596, -1.1596, -1.1944,  ..., -1.0724, -1.0201, -1.0027],\n",
      "         ...,\n",
      "         [-0.9330, -0.9853, -1.0027,  ..., -0.7936, -0.7587, -0.7238],\n",
      "         [-0.9330, -0.9853, -1.0027,  ..., -0.7761, -0.7587, -0.7238],\n",
      "         [-0.9330, -0.9853, -1.0201,  ..., -0.7936, -0.7761, -0.7413]]]), 0], [tensor([[[-0.5082, -0.5596, -0.5767,  ..., -0.6794, -0.6109, -0.5596],\n",
      "         [-0.5253, -0.5596, -0.5767,  ..., -0.6965, -0.6452, -0.5767],\n",
      "         [-0.5253, -0.5596, -0.5767,  ..., -0.6965, -0.6452, -0.5767],\n",
      "         ...,\n",
      "         [-0.4226, -0.4397, -0.4568,  ..., -0.3541, -0.3541, -0.3712],\n",
      "         [-0.4226, -0.4226, -0.4397,  ..., -0.3712, -0.3541, -0.3541],\n",
      "         [-0.4054, -0.4226, -0.4397,  ..., -0.3712, -0.3712, -0.3712]],\n",
      "\n",
      "        [[-0.5476, -0.5826, -0.6001,  ..., -0.6877, -0.6527, -0.6001],\n",
      "         [-0.5476, -0.5826, -0.6001,  ..., -0.6877, -0.6527, -0.6001],\n",
      "         [-0.5651, -0.6001, -0.6001,  ..., -0.6877, -0.6527, -0.6001],\n",
      "         ...,\n",
      "         [-0.5301, -0.5476, -0.5476,  ..., -0.4776, -0.4951, -0.4951],\n",
      "         [-0.5301, -0.5301, -0.5476,  ..., -0.4951, -0.4951, -0.4951],\n",
      "         [-0.5126, -0.5301, -0.5476,  ..., -0.4951, -0.4951, -0.5126]],\n",
      "\n",
      "        [[-0.5321, -0.5495, -0.5495,  ..., -0.6715, -0.6367, -0.6018],\n",
      "         [-0.5321, -0.5495, -0.5495,  ..., -0.6541, -0.6367, -0.6193],\n",
      "         [-0.5321, -0.5495, -0.5495,  ..., -0.6541, -0.6367, -0.6018],\n",
      "         ...,\n",
      "         [-0.5495, -0.5321, -0.5670,  ..., -0.5321, -0.5321, -0.5321],\n",
      "         [-0.5321, -0.5321, -0.5495,  ..., -0.5321, -0.5321, -0.5321],\n",
      "         [-0.5321, -0.5321, -0.5670,  ..., -0.5495, -0.5321, -0.5321]]]), 0], [tensor([[[ 0.1083, -0.0458, -0.2342,  ..., -0.2684, -0.1999, -0.0972],\n",
      "         [ 0.0056, -0.1314, -0.2513,  ..., -0.2684, -0.1999, -0.0972],\n",
      "         [-0.0801, -0.1314, -0.2513,  ..., -0.2684, -0.1999, -0.0972],\n",
      "         ...,\n",
      "         [-0.1999, -0.2171, -0.2171,  ...,  0.5364,  0.5536,  0.5707],\n",
      "         [-0.1999, -0.2171, -0.2342,  ...,  0.5364,  0.5364,  0.5364],\n",
      "         [-0.1828, -0.2171, -0.2342,  ...,  0.5364,  0.5536,  0.5364]],\n",
      "\n",
      "        [[ 0.2227,  0.0651, -0.1450,  ..., -0.1625, -0.0924, -0.0049],\n",
      "         [ 0.1176, -0.0224, -0.1625,  ..., -0.1450, -0.0749,  0.0126],\n",
      "         [ 0.0476, -0.0049, -0.1450,  ..., -0.1450, -0.0749,  0.0301],\n",
      "         ...,\n",
      "         [-0.1450, -0.1625, -0.1800,  ...,  0.5203,  0.5553,  0.5728],\n",
      "         [-0.1450, -0.1800, -0.1975,  ...,  0.5203,  0.5378,  0.5378],\n",
      "         [-0.1275, -0.1625, -0.1975,  ...,  0.5203,  0.5378,  0.5378]],\n",
      "\n",
      "        [[ 0.3393,  0.1651, -0.0441,  ..., -0.0790, -0.0092,  0.0779],\n",
      "         [ 0.2348,  0.0779, -0.0615,  ..., -0.0615,  0.0082,  0.0953],\n",
      "         [ 0.1476,  0.0953, -0.0441,  ..., -0.0615,  0.0082,  0.1302],\n",
      "         ...,\n",
      "         [-0.0615, -0.0615, -0.0790,  ...,  0.6182,  0.6531,  0.6705],\n",
      "         [-0.0441, -0.0615, -0.0964,  ...,  0.6182,  0.6356,  0.6531],\n",
      "         [-0.0092, -0.0441, -0.0964,  ...,  0.6182,  0.6356,  0.6531]]]), 0], [tensor([[[ 1.1872,  1.1187,  1.0331,  ...,  0.8618,  0.9303,  1.0159],\n",
      "         [ 1.1872,  1.1015,  1.0331,  ...,  0.8447,  0.8961,  0.9817],\n",
      "         [ 1.1700,  1.1015,  1.0331,  ...,  0.8447,  0.8961,  0.9646],\n",
      "         ...,\n",
      "         [ 0.1597,  0.1768,  0.1597,  ...,  0.4337,  0.4508,  0.4679],\n",
      "         [ 0.1083,  0.1254,  0.1083,  ...,  0.4337,  0.4337,  0.4679],\n",
      "         [ 0.0227,  0.0398,  0.0569,  ...,  0.4337,  0.4508,  0.4679]],\n",
      "\n",
      "        [[ 1.3782,  1.3081,  1.2206,  ...,  1.0630,  1.1331,  1.2031],\n",
      "         [ 1.3782,  1.2906,  1.2206,  ...,  1.0280,  1.0980,  1.1856],\n",
      "         [ 1.3782,  1.2906,  1.2206,  ...,  1.0280,  1.0980,  1.1681],\n",
      "         ...,\n",
      "         [ 0.1352,  0.1527,  0.1352,  ...,  0.3627,  0.3803,  0.3978],\n",
      "         [ 0.0826,  0.1176,  0.1001,  ...,  0.3627,  0.3803,  0.3978],\n",
      "         [-0.0049,  0.0301,  0.0476,  ...,  0.3627,  0.3627,  0.3803]],\n",
      "\n",
      "        [[ 1.4722,  1.3677,  1.2631,  ...,  1.1062,  1.1585,  1.2282],\n",
      "         [ 1.4548,  1.3502,  1.2631,  ...,  1.0888,  1.1411,  1.2108],\n",
      "         [ 1.4374,  1.3502,  1.2631,  ...,  1.0888,  1.1411,  1.1934],\n",
      "         ...,\n",
      "         [ 0.2696,  0.2871,  0.2871,  ...,  0.4091,  0.4265,  0.4614],\n",
      "         [ 0.2348,  0.2696,  0.2522,  ...,  0.4091,  0.4265,  0.4614],\n",
      "         [ 0.1476,  0.1825,  0.1999,  ...,  0.4265,  0.4265,  0.4439]]]), 0], [tensor([[[-0.2513, -0.3027, -0.3541,  ..., -0.2856, -0.1828, -0.0116],\n",
      "         [-0.2342, -0.2856, -0.3883,  ..., -0.2684, -0.1999, -0.0287],\n",
      "         [-0.2171, -0.2684, -0.4226,  ..., -0.2513, -0.1999, -0.0629],\n",
      "         ...,\n",
      "         [-0.0116, -0.0116, -0.0116,  ...,  0.1597,  0.1426,  0.1426],\n",
      "         [-0.0116, -0.0116, -0.0116,  ...,  0.1597,  0.1426,  0.1426],\n",
      "         [-0.0116, -0.0116, -0.0116,  ...,  0.1597,  0.1426,  0.1426]],\n",
      "\n",
      "        [[-0.2675, -0.3200, -0.3725,  ..., -0.3375, -0.2325, -0.0399],\n",
      "         [-0.2500, -0.2850, -0.4076,  ..., -0.3200, -0.2500, -0.0749],\n",
      "         [-0.2325, -0.2850, -0.4251,  ..., -0.2850, -0.2500, -0.1099],\n",
      "         ...,\n",
      "         [-0.0749, -0.0749, -0.0749,  ...,  0.1352,  0.1352,  0.1176],\n",
      "         [-0.0749, -0.0749, -0.0749,  ...,  0.1352,  0.1352,  0.1176],\n",
      "         [-0.0749, -0.0749, -0.0749,  ...,  0.1352,  0.1352,  0.1352]],\n",
      "\n",
      "        [[-0.3753, -0.4101, -0.4450,  ..., -0.3753, -0.2707, -0.1312],\n",
      "         [-0.3753, -0.3927, -0.4798,  ..., -0.3404, -0.2881, -0.1487],\n",
      "         [-0.3753, -0.3927, -0.5147,  ..., -0.3230, -0.2881, -0.1835],\n",
      "         ...,\n",
      "         [-0.1312, -0.1312, -0.1487,  ...,  0.0605,  0.0431,  0.0256],\n",
      "         [-0.1487, -0.1487, -0.1487,  ...,  0.0605,  0.0605,  0.0431],\n",
      "         [-0.1487, -0.1487, -0.1487,  ...,  0.0779,  0.0779,  0.0605]]]), 0], [tensor([[[ 0.3309,  0.2796,  0.1597,  ..., -0.0287, -0.0287, -0.0116],\n",
      "         [ 0.2796,  0.2453,  0.1768,  ..., -0.0287, -0.0116,  0.0056],\n",
      "         [ 0.2453,  0.2624,  0.1768,  ..., -0.0116,  0.0056,  0.0227],\n",
      "         ...,\n",
      "         [-0.3883, -0.3883, -0.3883,  ..., -0.1314, -0.1314, -0.1143],\n",
      "         [-0.3712, -0.3712, -0.4054,  ..., -0.1486, -0.1486, -0.1486],\n",
      "         [-0.3541, -0.3712, -0.4054,  ..., -0.1486, -0.1314, -0.1486]],\n",
      "\n",
      "        [[ 0.4853,  0.4328,  0.3102,  ...,  0.1352,  0.1176,  0.1527],\n",
      "         [ 0.4328,  0.3978,  0.3452,  ...,  0.1352,  0.1527,  0.1527],\n",
      "         [ 0.4153,  0.4328,  0.3452,  ...,  0.1527,  0.1702,  0.1702],\n",
      "         ...,\n",
      "         [-0.1975, -0.1975, -0.1975,  ..., -0.0399, -0.0399, -0.0049],\n",
      "         [-0.1800, -0.1800, -0.1975,  ..., -0.0749, -0.0574, -0.0399],\n",
      "         [-0.1450, -0.1625, -0.1975,  ..., -0.0574, -0.0399, -0.0224]],\n",
      "\n",
      "        [[ 0.6356,  0.5659,  0.4439,  ...,  0.1999,  0.1651,  0.1825],\n",
      "         [ 0.5834,  0.5136,  0.4614,  ...,  0.1999,  0.1999,  0.1999],\n",
      "         [ 0.5311,  0.5485,  0.4614,  ...,  0.2173,  0.2173,  0.2173],\n",
      "         ...,\n",
      "         [-0.0441, -0.0441, -0.0441,  ...,  0.0605,  0.0953,  0.1128],\n",
      "         [-0.0092, -0.0267, -0.0441,  ...,  0.0431,  0.0779,  0.0953],\n",
      "         [ 0.0082, -0.0092, -0.0441,  ...,  0.0605,  0.0953,  0.1128]]]), 0], [tensor([[[-0.8507, -0.9020, -0.9534,  ..., -0.9192, -0.8849, -0.8678],\n",
      "         [-0.8678, -0.9192, -0.9363,  ..., -0.9534, -0.9020, -0.8678],\n",
      "         [-0.9020, -0.9192, -0.9363,  ..., -0.9877, -0.9192, -0.8849],\n",
      "         ...,\n",
      "         [-0.5596, -0.6109, -0.6452,  ..., -0.8678, -0.8678, -0.9020],\n",
      "         [-0.5767, -0.6109, -0.6452,  ..., -0.8335, -0.8678, -0.8849],\n",
      "         [-0.5938, -0.6281, -0.6452,  ..., -0.8507, -0.8678, -0.9020]],\n",
      "\n",
      "        [[-0.8277, -0.8627, -0.9153,  ..., -0.9153, -0.8803, -0.8803],\n",
      "         [-0.8452, -0.8803, -0.8978,  ..., -0.9503, -0.8978, -0.8803],\n",
      "         [-0.8627, -0.8803, -0.8978,  ..., -0.9853, -0.9153, -0.8803],\n",
      "         ...,\n",
      "         [-0.7752, -0.7927, -0.8102,  ..., -0.9853, -0.9853, -1.0203],\n",
      "         [-0.7752, -0.7927, -0.7927,  ..., -0.9678, -0.9853, -1.0028],\n",
      "         [-0.7752, -0.7927, -0.7927,  ..., -0.9678, -1.0028, -1.0028]],\n",
      "\n",
      "        [[-0.7413, -0.7761, -0.8284,  ..., -0.8458, -0.8284, -0.8284],\n",
      "         [-0.7587, -0.7936, -0.8110,  ..., -0.8807, -0.8284, -0.8110],\n",
      "         [-0.7587, -0.7936, -0.7936,  ..., -0.8981, -0.8284, -0.8110],\n",
      "         ...,\n",
      "         [-0.7064, -0.7064, -0.7238,  ..., -0.9678, -0.9330, -0.9678],\n",
      "         [-0.7064, -0.7064, -0.7238,  ..., -0.9504, -0.9504, -0.9504],\n",
      "         [-0.7064, -0.7064, -0.7238,  ..., -0.9504, -0.9678, -0.9504]]]), 0], [tensor([[[-0.0629, -0.2171, -0.3027,  ..., -0.0458, -0.0458, -0.0116],\n",
      "         [-0.1828, -0.2856, -0.2856,  ..., -0.0458, -0.0287, -0.0116],\n",
      "         [-0.2684, -0.2513, -0.2513,  ..., -0.0458, -0.0116,  0.0056],\n",
      "         ...,\n",
      "         [-0.3369, -0.3369, -0.3541,  ...,  0.0569,  0.0398,  0.0398],\n",
      "         [-0.3198, -0.3369, -0.3883,  ...,  0.0398,  0.0227,  0.0056],\n",
      "         [-0.3198, -0.3712, -0.4226,  ...,  0.0398,  0.0227,  0.0056]],\n",
      "\n",
      "        [[ 0.0651, -0.0924, -0.1800,  ...,  0.1176,  0.1001,  0.1352],\n",
      "         [-0.0399, -0.1450, -0.1450,  ...,  0.1176,  0.1352,  0.1352],\n",
      "         [-0.1275, -0.1099, -0.0924,  ...,  0.1352,  0.1527,  0.1527],\n",
      "         ...,\n",
      "         [-0.0924, -0.1099, -0.1275,  ...,  0.1877,  0.1702,  0.1877],\n",
      "         [-0.0749, -0.0924, -0.1450,  ...,  0.1877,  0.1702,  0.1702],\n",
      "         [-0.0924, -0.1275, -0.1975,  ...,  0.1702,  0.1877,  0.1877]],\n",
      "\n",
      "        [[ 0.2173,  0.0605, -0.0267,  ...,  0.2348,  0.1999,  0.2348],\n",
      "         [ 0.1128, -0.0092,  0.0082,  ...,  0.2522,  0.2348,  0.2522],\n",
      "         [ 0.0082,  0.0256,  0.0431,  ...,  0.2522,  0.2696,  0.2696],\n",
      "         ...,\n",
      "         [ 0.1476,  0.1651,  0.1476,  ...,  0.3742,  0.3568,  0.3742],\n",
      "         [ 0.1825,  0.1651,  0.1128,  ...,  0.3568,  0.3568,  0.3568],\n",
      "         [ 0.1825,  0.1302,  0.0605,  ...,  0.3742,  0.3742,  0.3742]]]), 0], [tensor([[[-1.2103, -1.3130, -1.4158,  ..., -1.1247, -1.0733, -1.0048],\n",
      "         [-1.1932, -1.3130, -1.4158,  ..., -1.1418, -1.0904, -1.0219],\n",
      "         [-1.1589, -1.2788, -1.3987,  ..., -1.1418, -1.1075, -1.0219],\n",
      "         ...,\n",
      "         [ 0.1939,  0.1939,  0.1939,  ...,  0.2624,  0.2624,  0.2624],\n",
      "         [ 0.2111,  0.1939,  0.1939,  ...,  0.2624,  0.2624,  0.2624],\n",
      "         [ 0.2111,  0.1939,  0.1768,  ...,  0.2796,  0.2796,  0.2624]],\n",
      "\n",
      "        [[-1.1954, -1.3004, -1.3704,  ..., -1.0728, -1.0028, -0.9328],\n",
      "         [-1.1954, -1.2829, -1.3704,  ..., -1.0728, -1.0203, -0.9328],\n",
      "         [-1.1604, -1.2479, -1.3704,  ..., -1.0728, -1.0378, -0.9503],\n",
      "         ...,\n",
      "         [ 0.2227,  0.2227,  0.2052,  ...,  0.1877,  0.1877,  0.1877],\n",
      "         [ 0.2227,  0.2052,  0.2052,  ...,  0.1877,  0.1877,  0.1877],\n",
      "         [ 0.2402,  0.2227,  0.2052,  ...,  0.1877,  0.1877,  0.1877]],\n",
      "\n",
      "        [[-1.1421, -1.2119, -1.2467,  ..., -0.9678, -0.9156, -0.8633],\n",
      "         [-1.1247, -1.2119, -1.2467,  ..., -0.9853, -0.9330, -0.8633],\n",
      "         [-1.1073, -1.1770, -1.2467,  ..., -0.9853, -0.9504, -0.8807],\n",
      "         ...,\n",
      "         [ 0.1651,  0.1651,  0.1476,  ...,  0.1651,  0.1476,  0.1476],\n",
      "         [ 0.1651,  0.1651,  0.1651,  ...,  0.1651,  0.1476,  0.1476],\n",
      "         [ 0.1825,  0.1651,  0.1651,  ...,  0.1651,  0.1651,  0.1651]]]), 0], [tensor([[[-0.6623, -0.7479, -0.7993,  ..., -0.9534, -0.8849, -0.7479],\n",
      "         [-0.6965, -0.7650, -0.8164,  ..., -0.9534, -0.9192, -0.7993],\n",
      "         [-0.7137, -0.7993, -0.8164,  ..., -0.9363, -0.9192, -0.8335],\n",
      "         ...,\n",
      "         [ 0.5193,  0.5193,  0.5022,  ...,  0.2624,  0.2453,  0.2453],\n",
      "         [ 0.5022,  0.4851,  0.4679,  ...,  0.2624,  0.2624,  0.2453],\n",
      "         [ 0.5193,  0.4851,  0.4679,  ...,  0.2624,  0.2624,  0.2624]],\n",
      "\n",
      "        [[-0.6702, -0.7402, -0.7927,  ..., -0.9153, -0.8452, -0.7052],\n",
      "         [-0.6877, -0.7577, -0.7927,  ..., -0.8978, -0.8627, -0.7402],\n",
      "         [-0.7052, -0.7752, -0.8102,  ..., -0.8803, -0.8627, -0.7927],\n",
      "         ...,\n",
      "         [ 0.4153,  0.3978,  0.3978,  ...,  0.0476,  0.0476,  0.0476],\n",
      "         [ 0.3803,  0.3627,  0.3627,  ...,  0.0476,  0.0476,  0.0301],\n",
      "         [ 0.3978,  0.3803,  0.3627,  ...,  0.0651,  0.0476,  0.0476]],\n",
      "\n",
      "        [[-0.6193, -0.6715, -0.7064,  ..., -0.7936, -0.7413, -0.6541],\n",
      "         [-0.6367, -0.7064, -0.7238,  ..., -0.7761, -0.7587, -0.6890],\n",
      "         [-0.6541, -0.7064, -0.7238,  ..., -0.7587, -0.7587, -0.7064],\n",
      "         ...,\n",
      "         [ 0.2871,  0.2871,  0.2871,  ..., -0.0615, -0.0615, -0.0615],\n",
      "         [ 0.2522,  0.2696,  0.2696,  ..., -0.0615, -0.0615, -0.0615],\n",
      "         [ 0.2696,  0.2696,  0.2696,  ..., -0.0441, -0.0441, -0.0441]]]), 0], [tensor([[[ 1.4783,  1.4440,  1.3927,  ...,  1.0673,  1.1700,  1.3070],\n",
      "         [ 1.4612,  1.4098,  1.3927,  ...,  1.0502,  1.1358,  1.2557],\n",
      "         [ 1.4612,  1.4098,  1.3927,  ...,  1.0331,  1.1187,  1.2214],\n",
      "         ...,\n",
      "         [ 0.1254,  0.1254,  0.1254,  ...,  0.1768,  0.2282,  0.2624],\n",
      "         [ 0.0569,  0.1083,  0.1083,  ...,  0.0912,  0.1597,  0.2111],\n",
      "         [ 0.0056,  0.0741,  0.0912,  ..., -0.0116,  0.0227,  0.0398]],\n",
      "\n",
      "        [[ 1.6232,  1.5707,  1.5357,  ...,  1.1856,  1.2906,  1.4482],\n",
      "         [ 1.6057,  1.5532,  1.5182,  ...,  1.1506,  1.2556,  1.3782],\n",
      "         [ 1.5882,  1.5357,  1.5182,  ...,  1.1506,  1.2381,  1.3431],\n",
      "         ...,\n",
      "         [ 0.0826,  0.1001,  0.0826,  ...,  0.1176,  0.1702,  0.2227],\n",
      "         [ 0.0126,  0.0826,  0.0826,  ...,  0.0301,  0.1001,  0.1527],\n",
      "         [-0.0224,  0.0476,  0.0651,  ..., -0.0749, -0.0399, -0.0049]],\n",
      "\n",
      "        [[ 1.6117,  1.5420,  1.4897,  ...,  1.1585,  1.2631,  1.3851],\n",
      "         [ 1.5768,  1.5071,  1.4897,  ...,  1.1411,  1.2282,  1.3328],\n",
      "         [ 1.5594,  1.5071,  1.4897,  ...,  1.1237,  1.2108,  1.2980],\n",
      "         ...,\n",
      "         [ 0.2173,  0.2348,  0.2522,  ...,  0.2173,  0.2696,  0.3219],\n",
      "         [ 0.1651,  0.2348,  0.2696,  ...,  0.1128,  0.1825,  0.2522],\n",
      "         [ 0.1302,  0.2173,  0.2522,  ...,  0.0082,  0.0256,  0.0779]]]), 0], [tensor([[[1.5639, 1.4954, 1.4098,  ..., 1.1015, 1.1358, 1.1872],\n",
      "         [1.5639, 1.4783, 1.4098,  ..., 1.1015, 1.1187, 1.1700],\n",
      "         [1.5468, 1.4783, 1.4098,  ..., 1.1015, 1.1187, 1.1700],\n",
      "         ...,\n",
      "         [0.4508, 0.5022, 0.5364,  ..., 0.6734, 0.7077, 0.7419],\n",
      "         [0.4337, 0.5022, 0.5364,  ..., 0.5707, 0.6221, 0.6734],\n",
      "         [0.4166, 0.4851, 0.5193,  ..., 0.4166, 0.4508, 0.5022]],\n",
      "\n",
      "        [[1.7108, 1.6408, 1.5532,  ..., 1.2731, 1.2731, 1.3256],\n",
      "         [1.7108, 1.6232, 1.5532,  ..., 1.2731, 1.2731, 1.3081],\n",
      "         [1.7108, 1.6232, 1.5532,  ..., 1.2731, 1.2731, 1.3081],\n",
      "         ...,\n",
      "         [0.2577, 0.3277, 0.3627,  ..., 0.4678, 0.4853, 0.5203],\n",
      "         [0.2577, 0.3277, 0.3627,  ..., 0.3452, 0.3978, 0.4678],\n",
      "         [0.2402, 0.3102, 0.3277,  ..., 0.1877, 0.2227, 0.2927]],\n",
      "\n",
      "        [[1.8208, 1.7163, 1.6117,  ..., 1.3502, 1.3502, 1.4025],\n",
      "         [1.8034, 1.6988, 1.6117,  ..., 1.3502, 1.3502, 1.3851],\n",
      "         [1.7860, 1.6988, 1.6117,  ..., 1.3502, 1.3502, 1.3851],\n",
      "         ...,\n",
      "         [0.4091, 0.4788, 0.4962,  ..., 0.5311, 0.5659, 0.6008],\n",
      "         [0.4265, 0.4788, 0.4962,  ..., 0.4091, 0.4788, 0.5485],\n",
      "         [0.4091, 0.4614, 0.4788,  ..., 0.2522, 0.2871, 0.3568]]]), 0], [tensor([[[-0.8335, -0.8335, -0.8335,  ..., -0.7822, -0.7137, -0.6452],\n",
      "         [-0.8335, -0.8335, -0.8507,  ..., -0.7993, -0.7479, -0.6794],\n",
      "         [-0.8335, -0.8335, -0.8678,  ..., -0.7993, -0.7479, -0.6965],\n",
      "         ...,\n",
      "         [-0.5767, -0.5938, -0.6109,  ..., -0.6452, -0.6109, -0.5767],\n",
      "         [-0.5938, -0.6281, -0.6281,  ..., -0.6623, -0.6281, -0.6109],\n",
      "         [-0.6281, -0.6281, -0.6281,  ..., -0.6452, -0.6623, -0.6452]],\n",
      "\n",
      "        [[-0.9153, -0.9153, -0.8978,  ..., -0.8452, -0.7927, -0.7402],\n",
      "         [-0.9153, -0.9153, -0.9153,  ..., -0.8627, -0.8277, -0.7577],\n",
      "         [-0.8978, -0.9153, -0.9328,  ..., -0.8627, -0.8277, -0.7752],\n",
      "         ...,\n",
      "         [-0.7402, -0.7402, -0.7577,  ..., -0.7927, -0.7402, -0.6877],\n",
      "         [-0.7402, -0.7577, -0.7577,  ..., -0.8277, -0.7927, -0.7402],\n",
      "         [-0.7577, -0.7752, -0.7577,  ..., -0.8102, -0.8277, -0.7927]],\n",
      "\n",
      "        [[-0.9504, -0.9504, -0.9330,  ..., -0.8807, -0.8458, -0.7936],\n",
      "         [-0.9504, -0.9504, -0.9504,  ..., -0.8981, -0.8633, -0.8110],\n",
      "         [-0.9330, -0.9504, -0.9678,  ..., -0.8807, -0.8633, -0.8110],\n",
      "         ...,\n",
      "         [-0.7761, -0.7936, -0.7936,  ..., -0.8633, -0.8110, -0.7587],\n",
      "         [-0.7761, -0.7936, -0.7936,  ..., -0.9330, -0.8807, -0.8110],\n",
      "         [-0.7936, -0.7936, -0.8110,  ..., -0.9504, -0.9504, -0.8981]]]), 0], [tensor([[[-0.3883, -0.4226, -0.5082,  ..., -0.5596, -0.4397, -0.3541],\n",
      "         [-0.3712, -0.4226, -0.5082,  ..., -0.5596, -0.4568, -0.3712],\n",
      "         [-0.3541, -0.4226, -0.5082,  ..., -0.5938, -0.4911, -0.3883],\n",
      "         ...,\n",
      "         [ 0.3994,  0.3823,  0.3652,  ...,  0.3138,  0.3652,  0.3823],\n",
      "         [ 0.3823,  0.3481,  0.3309,  ...,  0.2453,  0.2624,  0.2967],\n",
      "         [ 0.3481,  0.3309,  0.3309,  ...,  0.1939,  0.2111,  0.2111]],\n",
      "\n",
      "        [[-0.4776, -0.4951, -0.5651,  ..., -0.6702, -0.5476, -0.4426],\n",
      "         [-0.4601, -0.4951, -0.5651,  ..., -0.6702, -0.5651, -0.4776],\n",
      "         [-0.4251, -0.4951, -0.5651,  ..., -0.7052, -0.6001, -0.5126],\n",
      "         ...,\n",
      "         [ 0.1527,  0.1352,  0.1176,  ...,  0.0826,  0.1176,  0.1527],\n",
      "         [ 0.1352,  0.1176,  0.1001,  ..., -0.0224,  0.0126,  0.0476],\n",
      "         [ 0.1176,  0.1001,  0.1001,  ..., -0.0749, -0.0574, -0.0399]],\n",
      "\n",
      "        [[-0.5844, -0.5670, -0.6193,  ..., -0.7936, -0.6890, -0.5844],\n",
      "         [-0.5495, -0.5670, -0.6193,  ..., -0.7936, -0.7064, -0.6193],\n",
      "         [-0.5147, -0.5670, -0.6193,  ..., -0.8284, -0.7413, -0.6715],\n",
      "         ...,\n",
      "         [ 0.0953,  0.0953,  0.0779,  ..., -0.0267,  0.0082,  0.0256],\n",
      "         [ 0.0779,  0.0605,  0.0605,  ..., -0.1312, -0.0964, -0.0615],\n",
      "         [ 0.0605,  0.0431,  0.0431,  ..., -0.1835, -0.1661, -0.1661]]]), 0]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17556\\2316716691.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17556\\2316716691.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#.cuda(non_blocking=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;31m#target = target#.cuda(non_blocking=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m             \u001b[1;31m#label.append(target.cpu()[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17556\\1278285112.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu_pool5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv6\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu6\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv7\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         )\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2434\u001b[0m         )\n\u001b[0;32m   2435\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2436\u001b[1;33m         \u001b[0m_verify_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2438\u001b[0m     return torch.batch_norm(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_verify_batch_size\u001b[1;34m(size)\u001b[0m\n\u001b[0;32m   2402\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2403\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2404\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expected more than 1 value per channel when training, got input size {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1, 1])"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # net definition \n",
    "    #net = AlexNet()\n",
    "    # net = Nets.ResNet(block = Nets.BasicBlock, layers = [2, 2, 2, 2], num_classes = 1).cuda()\n",
    "\n",
    "    # load pretrained model\n",
    "    #load_model(torch.load('AlexNet.pth', map_location=torch.device('cpu')), net) #load_model('pytorch-models/alexnet.pth')\n",
    "    # load_model(torch.load('./models/resnet18.pth'), net)\n",
    "\n",
    "    # evaluate\n",
    "    #net.eval()\n",
    "\n",
    "    # loading data...\n",
    "    #root = 'C:/Users/Lenovo/Documents/DTU-AP/SCUT-FBP5500_v2.1/SCUT-FBP5500_v2/Images'\n",
    "    #valdir = './data/1/test1.txt'\n",
    "    #root = 'C:/Users/Lenovo/Documents/DTU-AP/Multi-Morph/asian/af/asian_female_16'\n",
    "    #valdir = './data/1/morph16.txt'\n",
    "    #valdir = './data/1/test1.txt'\n",
    "    root = './data/morph16' #'C:/Users/Lenovo/Documents/AdvancedProject/NeuralNetwork/data/morph16'\n",
    "    valdir = './data/1/test16morph.txt'\n",
    "    \n",
    "    print('hér')\n",
    "    print(root, valdir)\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])  \n",
    "    val_dataset = read_img(root, valdir, transform=transform)\n",
    "    print(val_dataset)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        #label = [] #ÍBS: We don't need the label\n",
    "        pred = []\n",
    "\n",
    "        for i, (img, target) in enumerate(val_dataset):\n",
    "            img = img.unsqueeze(0)#.cuda(non_blocking=True)\n",
    "            #target = target#.cuda(non_blocking=True)\n",
    "            output = net(img).squeeze(0)\n",
    "            #label.append(target.cpu()[0])\n",
    "            pred.append(output.cpu()[0])\n",
    "            #print(i)\n",
    "\n",
    "        # measurements\n",
    "        #label = np.array(label) #ÍBS: don't need the label only the prediction\n",
    "        pred = np.array(pred)\n",
    "        #correlation = np.corrcoef(label, pred)[0][1]\n",
    "        #mae = np.mean(np.abs(label - pred))\n",
    "        #rmse = np.sqrt(np.mean(np.square(label - pred)))\n",
    "    \n",
    "    #print('\\n Label Array: ' + str(label))\n",
    "   # print('Label Mean: ' + str(label.mean()) + '\\n')\n",
    "    print('Prediction Array: ' + str(pred))\n",
    "    #print('Prediction Mean: ' + str(pred.mean()) + '\\n')\n",
    "    \n",
    "    #print('Correlation:{correlation:.4f}\\t'\n",
    "    #      'Mae:{mae:.4f}\\t'\n",
    "    #      'Rmse:{rmse:.4f}\\t'.format(\n",
    "    #        correlation=correlation, mae=mae, rmse=rmse))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de323f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
