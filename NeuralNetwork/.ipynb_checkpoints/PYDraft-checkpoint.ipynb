{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2cf20d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fdebc022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3b17231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## AlexNet ##################\n",
    "def bn_relu(inplanes):\n",
    "    return nn.Sequential(nn.BatchNorm2d(inplanes), nn.ReLU(inplace=True))\n",
    "\n",
    "def bn_relu_pool(inplanes, kernel_size=3, stride=2):\n",
    "    return nn.Sequential(nn.BatchNorm2d(inplanes), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=kernel_size, stride=stride))\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 96, kernel_size=11, stride=4, bias=False)\n",
    "        self.relu_pool1 = bn_relu_pool(inplanes=96)\n",
    "        self.conv2 = nn.Conv2d(96, 192, kernel_size=5, padding=2, groups=2, bias=False)\n",
    "        self.relu_pool2 = bn_relu_pool(inplanes=192)\n",
    "        self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1, groups=2, bias=False)\n",
    "        self.relu3 = bn_relu(inplanes=384)\n",
    "        self.conv4 = nn.Conv2d(384, 384, kernel_size=3, padding=1, groups=2, bias=False)\n",
    "        self.relu4 = bn_relu(inplanes=384)\n",
    "        self.conv5 = nn.Conv2d(384, 256, kernel_size=3, padding=1, groups=2, bias=False)\n",
    "        self.relu_pool5 = bn_relu_pool(inplanes=256)\n",
    "        # classifier\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=5, groups=2, bias=False)\n",
    "        self.relu6 = bn_relu(inplanes=256)\n",
    "        self.conv7 = nn.Conv2d(256, num_classes, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu_pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu_pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        x = self.relu4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu_pool5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5da10c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4), bias=False)\n",
       "  (relu_pool1): Sequential(\n",
       "    (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Conv2d(96, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2, bias=False)\n",
       "  (relu_pool2): Sequential(\n",
       "    (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "  (relu3): Sequential(\n",
       "    (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "  (relu4): Sequential(\n",
       "    (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "  (relu_pool5): Sequential(\n",
       "    (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv6): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), groups=2, bias=False)\n",
       "  (relu6): Sequential(\n",
       "    (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv7): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = AlexNet()\n",
    "net.load_state_dict(torch.load('./pytorch-models/cnn_ADAM_schlr.pth'))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5ed2fc60",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [138], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(valdir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrt\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m myfile: \u001b[38;5;66;03m# Open lorem.txt for reading text data.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m myline \u001b[38;5;129;01min\u001b[39;00m myfile:                \u001b[38;5;66;03m# For each line, stored as myline,\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m         mylines\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(myline\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m1\u001b[39m]))       \u001b[38;5;66;03m# add its contents to mylines.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(mylines)   \n\u001b[0;32m      9\u001b[0m min_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(mylines)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Scaling of data\n",
    "valdir = './data/1/test16morph.txt'\n",
    "mylines = []                             # Declare an empty list named mylines.\n",
    "with open(valdir, 'rt') as myfile: # Open lorem.txt for reading text data.\n",
    "    for myline in myfile:                # For each line, stored as myline,\n",
    "        mylines.append(float(myline.split()[1]))       # add its contents to mylines.\n",
    "print(mylines)   \n",
    "\n",
    "min_val = min(mylines)\n",
    "max_val = max(mylines)\n",
    "lower_scale = 0\n",
    "upper_scale = 4\n",
    "\n",
    "for i in range(len(mylines)):\n",
    "    mylines[i] = int(round(((upper_scale-lower_scale)*((mylines[i]-min_val)/(max_val-min_val)))+lower_scale))\n",
    "    \n",
    "print(mylines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8ea5bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(root, filedir, transform=None):\n",
    "    # Data loading\n",
    "    with open(filedir, 'r') as f:\n",
    "        lines = f.readlines()  \n",
    "    output = []    \n",
    "    for line in lines:\n",
    "        linesplit = line.split('\\n')[0].split(' ')\n",
    "        #print(linesplit)\n",
    "        addr = linesplit[0]\n",
    "        #target = torch.Tensor([float(linesplit[1])])\n",
    "        img = Image.open(os.path.join(root, addr)).convert('RGB')\n",
    "\n",
    "        if transform is not None:\n",
    "            img = transform(img)\n",
    "        \n",
    "        output.append([img, 0]) #√çBS: Changed target to 0\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "60dfa275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(pretrained_dict, new):\n",
    "    model_dict = new.state_dict()\n",
    "    #print(new.state_dict())\n",
    "    # 1. filter out unnecessary keys\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.state_dict().items() if k in model_dict}\n",
    "    # 2. overwrite entries in the existing state dict\n",
    "    model_dict.update(pretrained_dict)\n",
    "    new.load_state_dict(torch.load(model_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "13c4021d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Array: ['3']\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # net definition \n",
    "    #net = AlexNet()\n",
    "    # net = Nets.ResNet(block = Nets.BasicBlock, layers = [2, 2, 2, 2], num_classes = 1).cuda()\n",
    "\n",
    "    # load pretrained model\n",
    "    #load_model(torch.load('./pytorch-models/cnn_ADAM_schlr.pth', map_location=torch.device('cpu')), net) #load_model('pytorch-models/alexnet.pth')\n",
    "    # load_model(torch.load('./models/resnet18.pth'), net)\n",
    "    \n",
    "    # evaluate\n",
    "    #net.eval()\n",
    "    \n",
    "    #model = torch.load('./pytorch-models/cnn_ADAM_schlr.pth')\n",
    "    #model.eval()\n",
    "    #net = AlexNet()\n",
    "    #net.load_state_dict(torch.load('./pytorch-models/cnn_ADAM_schlr.pth'))\n",
    "    #net.eval()\n",
    "    # loading data...\n",
    "    #root = 'C:/Users/Lenovo/Documents/DTU-AP/SCUT-FBP5500_v2.1/SCUT-FBP5500_v2/Images'\n",
    "    #valdir = './data/1/test1.txt'\n",
    "    #root = 'C:/Users/Lenovo/Documents/DTU-AP/Multi-Morph/asian/af/asian_female_16'\n",
    "    #valdir = './data/1/morph16.txt'\n",
    "    #valdir = './data/1/test1.txt'\n",
    "    root = './data/input_test' #'C:/Users/Lenovo/Documents/AdvancedProject/NeuralNetwork/data/morph16'\n",
    "    valdir = './data/1/test16morph.txt'\n",
    "    \n",
    "    #test_image_dir = './data/input_test'\n",
    "    #test_image_filepath = os.path.join(test_image_dir, 'image5.png')\n",
    " \n",
    "    #print(root, valdir)\n",
    "    \n",
    "    \n",
    "    # Pre-process input image\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])  \n",
    "    val_dataset = read_img(root, valdir, transform=transform)\n",
    "    #print(val_dataset)\n",
    "    \n",
    "    net.eval()\n",
    "    \n",
    "    with open('./data/classes.txt') as f:\n",
    "            classes = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        #label = [] #√çBS: We don't need the label\n",
    "        pred = []\n",
    "        perc = []\n",
    "        c = []\n",
    "\n",
    "        for i, (img, target) in enumerate(val_dataset):\n",
    "            img = img.unsqueeze(0)#.cuda(non_blocking=True)\n",
    "            output = net(img).squeeze(1)\n",
    "            pred.append(output.cpu()[0])\n",
    "            #print(output.shape)\n",
    "            _, index = torch.max(output, 1)\n",
    "            percentage = torch.nn.functional.softmax(output, dim=1)[0] * 100\n",
    "            perc.append(percentage[index[0]].item())\n",
    "            c.append(classes[index[0]])\n",
    "            \n",
    "            \n",
    "        #print(output.shape)\n",
    "        \n",
    "        #with open('./data/classes.txt') as f:\n",
    "        #    classes = [line.strip() for line in f.readlines()]\n",
    "        \n",
    "        #_, index = torch.max(output, 1)\n",
    " \n",
    "        #percentage = torch.nn.functional.softmax(output, dim=1)[0] * 100\n",
    " \n",
    "        #print(classes[index[0]],percentage[index[0]].item())\n",
    "        \n",
    "        # √çBS: If you want to see the confidence of the other classes\n",
    "        #_, indices = torch.sort(output, descending=True)\n",
    "        #print([(classes[idx], percentage[idx].item()) for idx in indices[0][:5]])\n",
    "\n",
    "        # measurements\n",
    "        #label = np.array(label) #√çBS: don't need the label only the prediction\n",
    "        pred = np.array(c)\n",
    "\n",
    "    print('Prediction Array: ' + str(pred))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0620cb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
